<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>√áaƒüatay  Yƒ±ldƒ±z</title>
<meta name="description" content="My personal website
">

<!-- Open Graph -->

<meta property="og:site_name" content="My personal website
" />
<meta property="og:type" content="object" />
<meta property="og:title" content="" />
<meta property="og:url" content="/" />
<meta property="og:description" content="about" />
<meta property="og:image" content="" />


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>‚õπÔ∏è</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->

  <script src="/assets/js/theme.js"></script>
  <!-- Load DarkMode JS -->
<script src="/assets/js/dark_mode.js"></script>






    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
        <!-- Social Icons -->
        <div class="row ml-1 ml-sm-0">
          <span class="contact-icon text-center">
  <a href="mailto:%63%61%67%61%74%61%79.%79%69%6C%64%69%7A@%75%6E%69-%74%75%65%62%69%6E%67%65%6E.%64%65"><i class="fas fa-envelope"></i></a>
  
  <a href="https://scholar.google.com/citations?user=dNloPBUAAAAJ" target="_blank" title="Google Scholar"><i class="ai ai-google-scholar"></i></a>
  
  <a href="https://www.researchgate.net/profile/Cagatay-Yildiz/" target="_blank" title="ResearchGate"><i class="ai ai-researchgate"></i></a>
  <a href="https://github.com/cagatayyildiz" target="_blank" title="GitHub"><i class="fab fa-github"></i></a>
  
  <a href="https://twitter.com/CgtyYldz" target="_blank" title="Twitter"><i class="fab fa-twitter"></i></a>
  
  
  
  
  
  
  
</span>

        </div>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item active">
            <a class="nav-link" href="/">
              about
              
                <span class="sr-only">(current)</span>
              
            </a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item ">
            <a class="nav-link" href="/blog/">
              blog
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/notes/">
                ML Notes
                
              </a>
          </li>
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                publications
                
              </a>
          </li>
          
          
          
            <div class = "toggle-container">
              <a id = "light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">
     <span class="font-weight-bold">√áaƒüatay</span>  Yƒ±ldƒ±z
    </h1>
     <p class="desc"></p>
  </header>

  <article>
    
    <div class="profile float-right">
      
        <img class="img-fluid z-depth-1 rounded" src="/assets/img/prof_pic.png">
      
      
        <div class="address">
          <p>AI Research Building</p> <p>Maria-von-Linden-Str. 6</p> <p>72076 Tuebingen, Germany</p>

        </div>
      
    </div>
    

    <div class="clearfix">
      <p>I‚Äôm a postdoctoral researcher at the <a href="http://bethgelab.org/" target="\_blank">Bethge Lab</a>, University of Tuebingen. During my doctoral studies, I was supervised by <a href="https://users.ics.aalto.fi/harrila/" target="\_blank">Harri L√§hdesm√§ki</a> at Aalto University, Finland. Before that, I worked with <a href="https://www.cmpe.boun.edu.tr/~cemgil/" target="\_blank">Taylan Cemgil</a> in my Master‚Äôs degree at Bogazici University, Istanbul.</p>

<p>My postdoctoral studies are about a mixed bag of machine learning models. I work on</p>
<ul>
  <li>Lie auto-encoders with <a href="https://www.imperial.ac.uk/people/t.birdal">Tolga</a> and <a href="https://bethgelab.org/">Matthias</a>.</li>
  <li>lifelong disentangled learning with <a href="https://scholar.google.com/citations?user=8vAIQXoAAAAJ&amp;hl=en">Sebastian</a> and <a href="https://bethgelab.org/">Matthias</a>.</li>
  <li>continual large language models with <a href="https://cohere.for.ai/#who-we-are">Beyza</a>.</li>
  <li>representations for dynamical systems with <a href="https://scholar.google.com/citations?hl=en&amp;user=AJIXYb0AAAAJ">Ilze</a>, <a href="https://saramagliacane.github.io/">Sara</a>, <a href="https://www.egavves.com/">Stratis</a>, and <a href="https://bethgelab.org/">Matthias</a>.</li>
  <li>diffusion-based adversarial purification <a href="https://cmpe.boun.edu.tr/~incibaytas/">Inci</a>.</li>
</ul>

<p>My name is super easy to pronounce: <a href="https://forvo.com/word/%C3%A7a%C4%9Fatay/" target="\_blank">chaa-tai</a>.</p>

<p>Check out <a href="https://users.aalto.fi/~heinom10/guidelines.html" target="\_blank">Markus‚Äô guideline for PhD students</a>.</p>

    </div>

    
      <div class="news">
  <h2>news</h2>
  
    <div class="table-responsive">
      <table class="table table-sm table-borderless">
      
      
        <tr>
          <th scope="row">Oct 28, 2023</th>
          <td>
            
              üë®‚Äçüíª <a href="https://arxiv.org/abs/2302.13262" target="\_blank">Modulated neural ODEs paper</a> accepted to NeurIPS 2023!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Jul 27, 2023</th>
          <td>
            
              üé§ Organized a summer school on <a href="https://bilimler.org/event/guncel-yapay-zeka-ve-matematiksel-temelleri/">ML and mathematical foundations</a> in <a href="https://bilimler.org/">Bilimler K√∂y√º</a>.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Feb 6, 2023</th>
          <td>
            
              üé§ Talks on <a href="https://cagatayyildiz.github.io/notes/pca-ae-vae/">PCA/VAEs</a> and <a href="https://cagatayyildiz.github.io/notes/diff-models/">diffusion models</a> in <a href="https://nesinkoyleri.org/events/2023-yapay-ogrenme-icin-matematik/">Nesin Village</a>.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Nov 6, 2022</th>
          <td>
            
              ü•≥ <a href="https://openreview.net/pdf?id=vj9vS27Gq6P" target="\_blank">Latent diverge-free GP-ODE paper</a> accepted to <a href="https://sites.google.com/view/caudyn2022/home" target="\_blank">causal dynamics workshop at NeurIPS</a>!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Oct 6, 2022</th>
          <td>
            
              ü•≥  <a href="https://arxiv.org/pdf/2205.11894.pdf" target="\_blank">Interacting Dynamical Systems paper</a> accepted to NeurIPS 2022!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Jul 23, 2022</th>
          <td>
            
              üé§ Talk on continuous-time RL at <a href="https://sites.google.com/view/continuous-time-methods-icml/home" target="\_blank">ICML 2022 workshop on continuous-time methods</a>.


            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Jun 17, 2022</th>
          <td>
            
              üé§ <a href="https://www.youtube.com/watch?v=oh2X89rmMdQ" target="\_blank">Talk</a> on neural ODEs at <a href="https://probabilistic.ai/" target="\_blank">Nordic Probabilistic AI School</a>. Lecture material <a href="https://github.com/cagatayyildiz/neural-ode-tutorial">here</a>.


            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Jun 1, 2022</th>
          <td>
            
              üë®‚Äçüíª Starting as a postdoc in <a href="http://bethgelab.org/" target="\_blank">Bethge Lab</a> in Tuebingen!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">May 16, 2022</th>
          <td>
            
              üéâ Paper accepted to UAI 2022, read it <a href="https://arxiv.org/pdf/2106.10905.pdf" target="\_blank">here</a>

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Apr 27, 2022</th>
          <td>
            
              üé§  Talk on neural ODEs at <a href="https://www.ida.liu.se/research/machinelearning/seminars/" target="\_blank">Linkoping University ML seminars</a>.


            
          </td>
        </tr>
      
      </table>
    </div>
  
</div>

    

    
      <div class="publications">
  <h2>selected publications</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">submitted</abbr>
    
  
  </div>

  <div id="auzina2023invariant" class="col-sm-8">
    
      <div class="title">Invariant Neural Ordinary Differential Equations</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Auzina, Ilze Amanda,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Yƒ±ldƒ±z, √áaƒüatay</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Magliacane, Sara,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Bethge, Matthias,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Gavves, Efstratios
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Advances in Neural Information Processing Systems</em>
      
      
        2023
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      
      <a href="https://arxiv.org/pdf/2302.13262.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Latent neural ordinary differential equations have been proven useful for learning non-linear dynamics of arbitrary sequences. In contrast with their mechanistic counterparts, the predictive accuracy of neural ODEs decreases over longer prediction horizons (Rubanova et al., 2019). To mitigate this issue, we propose disentangling dynamic states from time-invariant variables in a completely data-driven way, enabling robust neural ODE models that can generalize across different settings. We show that such variables can control the latent differential function and/or parameterize the mapping from latent variables to observations. By explicitly modeling the time-invariant variables, our framework enables the use of recent advances in representation learning. We demonstrate this by introducing a straightforward self-supervised objective that enhances the learning of these variables. The experiments on low-dimensional oscillating systems and video sequences reveal that our disentangled model achieves improved longterm predictions, when the training data involve sequence-specific factors of variation such as different rotational speeds, calligraphic styles, and friction constants.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ICLR</abbr>
    
  
  </div>

  <div id="iakovlev2022latent" class="col-sm-8">
    
      <div class="title">Latent Neural ODEs with Sparse Bayesian Multiple Shooting</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Iakovlev, Valerii,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Yƒ±ldƒ±z, √áaƒüatay</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Heinonen, Markus,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and L√§hdesm√§ki, Harri
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In International Conference on Learning Representations</em>
      
      
        2023
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      
      <a href="https://openreview.net/pdf?id=moIlFZfj_1b" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Training dynamic models, such as neural ODEs, on long trajectories is a hard problem that requires using various tricks, such as trajectory splitting, to make model training work in practice. These methods are often heuristics with poor theoretical justifications, and require iterative manual tuning. We propose a principled multiple shooting technique for neural ODEs that splits the trajectories into manageable short segments, which are optimised in parallel, while ensuring probabilistic control on continuity over consecutive segments. We derive variational inference for our shooting-based latent neural ODE models and propose amortized encodings of irregularly sampled trajectories with a transformer-based recognition network with temporal attention and relative positional encoding. We demonstrate efficient and stable training, and state-of-the-art performance on multiple large-scale benchmark datasets.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">NeurIPS</abbr>
    
  
  </div>

  <div id="yildiz2022learning" class="col-sm-8">
    
      <div class="title">Learning Interacting Dynamical Systems with Latent Gaussian Process ODEs</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Yƒ±ldƒ±z, √áaƒüatay</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Kandemir, Melih,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Rakitsch, Barbara
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Advances in Neural Information Processing Systems</em>
      
      
        2022
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      
      <a href="https://arxiv.org/pdf/2205.11894.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/boschresearch/iGPODE" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We study uncertainty-aware modeling of continuous-time dynamics of interacting objects. We introduce a new model that decomposes independent dynamics of single objects accurately from their interactions. By employing latent Gaussian process ordinary differential equations, our model infers both independent dynamics and their interactions with reliable uncertainty estimates. In our formulation, each object is represented as a graph node and interactions are modeled by accumulating the messages coming from neighboring objects. We show that efficient inference of such a complex network of variables is possible with modern variational sparse Gaussian process inference techniques. We empirically demonstrate that our model improves the reliability of long-term predictions over neural network based alternatives and it successfully handles missing dynamic or static information. Furthermore, we observe that only our model can successfully encapsulate independent dynamics and interaction information in distinct functions and show the benefit from this disentanglement in extrapolation scenarios.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">UAI</abbr>
    
  
  </div>

  <div id="hegde2021bayesian" class="col-sm-8">
    
      <div class="title">Variational multiple shooting for Bayesian ODEs with Gaussian processes</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Hedge, Pashupati,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Yƒ±ldƒ±z, √áaƒüatay</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Lahdesmaki, Harri,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Kaski, Samuel,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Heinonen, Markus
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Uncertainty in Artificial Intelligence</em>
      
      
        2022
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      
      <a href="https://arxiv.org/pdf/2106.10905.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/hegdepashupati/gaussian-process-odes" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Recent machine learning advances have proposed black-box estimation of unknown continuous-time system dynamics directly from data. However, earlier works are based on approximative ODE solutions or point estimates. We propose a novel Bayesian nonparametric model that uses Gaussian processes to infer posteriors of unknown ODE systems directly from data. We derive sparse variational inference with decoupled functional sampling to represent vector field posteriors. We also introduce a probabilistic shooting augmentation to enable efficient inference from arbitrarily long trajectories. The method demonstrates the benefit of computing vector field posteriors, with predictive uncertainty scores outperforming alternative methods on multiple ODE learning tasks.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">thesis</abbr>
    
  
  </div>

  <div id="Yƒ±ldƒ±z2022" class="col-sm-8">
    
      <div class="title">Differential Equations for Machine Learning</div>
      <div class="author">
        
          
          
          
          
          
          
            
              <em>Yƒ±ldƒ±z, √áaƒüatay</em>
            
          
        
      </div>

      <div class="periodical">
      
      
        2022
      
      </div>
    

    <div class="links">
    
    
    
      <a href="http://urn.fi/URN:ISBN:978-952-64-0666-4" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="https://aaltodoc.aalto.fi/bitstream/handle/123456789/112291/isbn9789526406664.pdf?sequence=1&isAllowed=y" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ICML</abbr>
    
  
  </div>

  <div id="yildiz2021continuous" class="col-sm-8">
    
      <div class="title">Continuous-time Model-based Reinforcement Learning</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Yƒ±ldƒ±z, √áaƒüatay</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Heinonen, Markus,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Lahdesmaki, Harri
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In International Conference on Machine Learning</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      
      <a href="https://arxiv.org/pdf/2102.04764.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/cagatayyildiz/oderl" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Model-based reinforcement learning (MBRL) approaches rely on discrete-time state transition models whereas physical systems and the vast majority of control tasks operate in continuous-time. To avoid time-discretization approximation of the underlying process, we propose a continuous-time MBRL framework based on a novel actor-critic method. Our approach also infers the unknown state evolution differentials with Bayesian neural ordinary differential equations (ODE) to account for epistemic uncertainty. We implement and test our method on a new ODE-RL suite that explicitly solves continuous-time control systems. Our experiments illustrate that the model is robust against irregular and noisy data, is sample-efficient, and can solve control problems which pose challenges to discrete-time MBRL methods. </p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">NeurIPS</abbr>
    
  
  </div>

  <div id="yildiz2019deep" class="col-sm-8">
    
      <div class="title">ODE2VAE: Deep generative second order ODEs with Bayesian neural networks</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Yƒ±ldƒ±z, √áaƒüatay</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Heinonen, Markus,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Lahdesmaki, Harri
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Advances in Neural Information Processing Systems</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://papers.nips.cc/paper/2019/hash/99a401435dcb65c4008d3ad22c8cdad0-Abstract.html" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="https://papers.nips.cc/paper/2019/file/99a401435dcb65c4008d3ad22c8cdad0-Paper.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
      
      <a href="https://papers.nips.cc/paper/2019/file/99a401435dcb65c4008d3ad22c8cdad0-Supplemental.zip" class="btn btn-sm z-depth-0" role="button" target="_blank">Supp</a>
      
    
    
    
      <a href="https://github.com/cagatayyildiz/ODE2VAE" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
      
      <a href="https://github.com/cagatayyildiz/ODE2VAE/blob/master/ode2vae_poster.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a>
      
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We present Ordinary Differential Equation Variational Auto-Encoder (ODE2VAE), a latent second order ODE model for high-dimensional sequential data. Leveraging the advances in deep generative models, ODE2VAE can simultaneously learn the embedding of high dimensional trajectories and infer arbitrarily complex continuous-time latent dynamics. Our model explicitly decomposes the latent space into momentum and position components and solves a second order ODE system, which is in contrast to recurrent neural network (RNN) based time series models and recently proposed black-box ODE techniques. In order to account for uncertainty, we propose probabilistic latent ODE dynamics parameterized by deep Bayesian neural networks. We demonstrate our approach on motion capture, image rotation, and bouncing balls datasets. We achieve state-of-the-art performance in long term motion prediction and imputation tasks.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ICML</abbr>
    
  
  </div>

  <div id="heinonen18learning" class="col-sm-8">
    
      <div class="title">Learning unknown ODE models with Gaussian processes</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Heinonen, Markus,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Yƒ±ldƒ±z, √áaƒüatay</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Mannerstr√∂m, Henrik,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Intosalmi, Jukka,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and L√§hdesm√§ki, Harri
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In International Conference on Machine Learning</em>
      
      
        2018
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://papers.nips.cc/paper/2019/hash/99a401435dcb65c4008d3ad22c8cdad0-Abstract.html" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="http://proceedings.mlr.press/v80/heinonen18a/heinonen18a.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
      
      <a href="http://proceedings.mlr.press/v80/heinonen18a/heinonen18a-supp.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Supp</a>
      
    
    
    
      <a href="https://github.com/cagatayyildiz/npde/" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
      
      <a href="https://github.com/cagatayyildiz/npde/blob/master/npode_poster.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a>
      
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>In conventional ODE modelling coefficients of an equation driving the system state forward in time are estimated. However, for many complex systems it is practically impossible to determine the equations or interactions governing the underlying dynamics. In these settings, parametric ODE model cannot be formulated. Here, we overcome this issue by introducing a novel paradigm of nonparametric ODE modelling that can learn the underlying dynamics of arbitrary continuous-time systems without prior knowledge. We propose to learn non-linear, unknown differential functions from state observations using Gaussian process vector fields within the exact ODE formalism. We demonstrate the model‚Äôs capabilities to infer dynamics from sparse data and to simulate the system forward into future.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ICML</abbr>
    
  
  </div>

  <div id="simsekli18learning" class="col-sm-8">
    
      <div class="title">Asynchronous Stochastic Quasi-Newton MCMC for Non-Convex Optimization</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Simsekli, Umut,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Yƒ±ldƒ±z, √áaƒüatay</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Nguyen, Than Huy,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Cemgil, Taylan,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Richard, Gael
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In International Conference on Machine Learning</em>
      
      
        2018
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="http://proceedings.mlr.press/v80/simsekli18a" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="http://proceedings.mlr.press/v80/simsekli18a/simsekli18a.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
      
      <a href="http://proceedings.mlr.press/v80/simsekli18a/simsekli18a-supp.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Supp</a>
      
    
    
    
    
      
      <a href="/assets/pdf/aslbfgs_poster.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a>
      
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Recent studies have illustrated that stochastic gradient Markov Chain Monte Carlo techniques have a strong potential in non-convex optimization, where local and global convergence guarantees can be shown under certain conditions. By building up on this recent theory, in this study, we develop an asynchronous-parallel stochastic L-BFGS algorithm for non-convex optimization. The proposed algorithm is suitable for both distributed and shared-memory settings. We provide formal theoretical analysis and show that the proposed method achieves an ergodic convergence rate of O(1/\sqrtN) (N being the total number of iterations) and it can achieve a linear speedup under certain conditions. We perform several experiments on both synthetic and real datasets. The results support our theory and show that the proposed algorithm provides a significant speedup over the recently proposed synchronous distributed L-BFGS algorithm.</p>
    </div>
    
  </div>
</div>
</li></ol>
</div>

    

    
    <div class="social">
      <span class="contact-icon text-center">
  <a href="mailto:%63%61%67%61%74%61%79.%79%69%6C%64%69%7A@%75%6E%69-%74%75%65%62%69%6E%67%65%6E.%64%65"><i class="fas fa-envelope"></i></a>
  
  <a href="https://scholar.google.com/citations?user=dNloPBUAAAAJ" target="_blank" title="Google Scholar"><i class="ai ai-google-scholar"></i></a>
  
  <a href="https://www.researchgate.net/profile/Cagatay-Yildiz/" target="_blank" title="ResearchGate"><i class="ai ai-researchgate"></i></a>
  <a href="https://github.com/cagatayyildiz" target="_blank" title="GitHub"><i class="fab fa-github"></i></a>
  
  <a href="https://twitter.com/CgtyYldz" target="_blank" title="Twitter"><i class="fab fa-twitter"></i></a>
  
  
  
  
  
  
  
</span>

      <div class="contact-note">Feel free to drop an e-mail on anything!
</div>
    </div>
    
  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="sticky-bottom mt-5">
  <div class="container">
    &copy; Copyright 2023 √áaƒüatay  Yƒ±ldƒ±z.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>

    
    
    Last updated: November 29, 2023.
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
