<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Ã‡aÄŸatay YÄ±ldÄ±z </title> <meta name="author" content="Ã‡aÄŸatay YÄ±ldÄ±z"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9B%B9%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://cagatayyildiz.github.io/"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?0afe9f0ae161375728f7bcc5eb5b4ab4"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/notes/">ML notes </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Ã‡aÄŸatay</span> YÄ±ldÄ±z </h1> <p class="desc"></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/profpic-480.webp 480w,/assets/img/profpic-800.webp 800w,/assets/img/profpic-1400.webp 1400w," sizes="(min-width: 800px) 231.0px, (min-width: 576px) 30vw, 95vw" type="image/webp"> <img src="/assets/img/profpic.png?0dc3267cdc9abee64cf94fcee2168922" class="img-fluid z-depth-1 rounded-circle" width="100%" height="auto" alt="profpic.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"> <p>AI Research Building</p> <p>Maria-von-Linden-Str. 6</p> <p>72076 Tuebingen, Germany</p> </div> </div> <div class="clearfix"> <p>Iâ€™m a postdoctoral researcher at the <a href="http://bethgelab.org/" target="\_blank" rel="external nofollow noopener">Bethge Lab</a>, University of Tuebingen. During my doctoral studies, I was supervised by <a href="https://users.ics.aalto.fi/harrila/" target="\_blank" rel="external nofollow noopener">Harri LÃ¤hdesmÃ¤ki</a> at Aalto University, Finland. Before that, I worked with <a href="https://www.cmpe.boun.edu.tr/~cemgil/" target="\_blank" rel="external nofollow noopener">Taylan Cemgil</a> in my Masterâ€™s degree at Bogazici University, Istanbul.</p> <p>My postdoctoral studies are about a mixed bag of machine learning models. I work on</p> <ul> <li>Lie auto-encoders with <a href="https://www.imperial.ac.uk/people/t.birdal" rel="external nofollow noopener" target="_blank">Tolga</a> and <a href="https://bethgelab.org/" rel="external nofollow noopener" target="_blank">Matthias</a>.</li> <li>identifiably dynamical systems with <a href="https://www.aalto.fi/en/people/caglar-hizli" rel="external nofollow noopener" target="_blank">Ã‡aÄŸlar</a> and <a href="https://scholar.google.com/citations?hl=en&amp;user=id47-5cAAAAJ" rel="external nofollow noopener" target="_blank">Pekka</a>.</li> <li>optimization for LLMs with Firat and <a href="https://scholar.google.com/citations?user=v2cMiCAAAAAJ&amp;hl=en&amp;oi=ao" rel="external nofollow noopener" target="_blank">Beyza</a>.</li> </ul> <p>Iâ€™m supervising three MSc theses:</p> <ul> <li>realistic online continual learning (with Joschka StrÃ¼ber).</li> <li>knowledge organization for continual question answering (with Atahan Ã–zer).</li> <li>mechanistic understanding of forgetting in LLMs (with Nitin Sharma).</li> </ul> <p>My name is super easy to pronounce: <a href="https://forvo.com/word/%C3%A7a%C4%9Fatay/" target="\_blank" rel="external nofollow noopener">chaa-tai</a>.</p> <p>Check out <a href="https://users.aalto.fi/~heinom10/guidelines.html" target="\_blank" rel="external nofollow noopener">Markusâ€™ guideline for PhD students</a>.</p> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Jul 09, 2024</th> <td> ğŸ¤ Talk on <a href="https://uni-tuebingen.de/en/research/core-research/cluster-of-excellence-machine-learning/events/events/#c2021889" rel="external nofollow noopener" target="_blank">6th Cluster Conference â€œMachine Learning in Scienceâ€</a>. My slides are <a href="https://github.com/cagatayyildiz/cagatayyildiz.github.io/blob/source/assets/pdf/ml_in_sci.pdf" rel="external nofollow noopener" target="_blank">here</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Jun 15, 2024</th> <td> ğŸ“ Two papers submitted to EMNLP 2024: <a href="https://arxiv.org/html/2402.17400v1" rel="external nofollow noopener" target="_blank">Investigating Continual Pretraining in LLMs</a> (stay tuned for the second preprint). </td> </tr> <tr> <th scope="row" style="width: 20%">May 26, 2024</th> <td> ğŸ“ <a href="https://arxiv.org/abs/2406.03337" rel="external nofollow noopener" target="_blank">Identifying latent state transition in non-linear dynamical systems</a> paper is submitted to NeurIPS 2024! </td> </tr> <tr> <th scope="row" style="width: 20%">May 20, 2024</th> <td> ğŸ“ <a href="https://arxiv.org/abs/2312.16731" rel="external nofollow noopener" target="_blank">Infinite dSprites for disentangled continual learning</a> is accepted to CoLLAs 2024! </td> </tr> <tr> <th scope="row" style="width: 20%">Dec 05, 2023</th> <td> ğŸ“œ I co-organized the first <a href="https://institute-tue.ellis.eu/en/events/tubingen-neurips-fest-2023" rel="external nofollow noopener" target="_blank">TÃ¼bingen pre-NeurIPS event</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Oct 28, 2023</th> <td> ğŸ‘¨â€ğŸ’» <a href="https://arxiv.org/abs/2302.13262" target="\_blank" rel="external nofollow noopener">Modulated neural ODEs paper</a> accepted to NeurIPS 2023! </td> </tr> <tr> <th scope="row" style="width: 20%">Jul 27, 2023</th> <td> ğŸ¤ Organized a summer school on <a href="https://bilimler.org/event/guncel-yapay-zeka-ve-matematiksel-temelleri/" rel="external nofollow noopener" target="_blank">ML and mathematical foundations</a> in <a href="https://bilimler.org/" rel="external nofollow noopener" target="_blank">Bilimler KÃ¶yÃ¼</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Feb 06, 2023</th> <td> ğŸ¤ Talks on <a href="https://cagatayyildiz.github.io/notes/pca-ae-vae/">PCA/VAEs</a> and <a href="https://cagatayyildiz.github.io/notes/diff-models/">diffusion models</a> in <a href="https://nesinkoyleri.org/events/2023-yapay-ogrenme-icin-matematik/" rel="external nofollow noopener" target="_blank">Nesin Village</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Nov 06, 2022</th> <td> ğŸ¥³ <a href="https://openreview.net/pdf?id=vj9vS27Gq6P" target="\_blank" rel="external nofollow noopener">Latent diverge-free GP-ODE paper</a> accepted to <a href="https://sites.google.com/view/caudyn2022/home" target="\_blank" rel="external nofollow noopener">causal dynamics workshop at NeurIPS</a>! </td> </tr> <tr> <th scope="row" style="width: 20%">Oct 06, 2022</th> <td> ğŸ¥³ <a href="https://arxiv.org/pdf/2205.11894.pdf" target="\_blank" rel="external nofollow noopener">Interacting Dynamical Systems paper</a> accepted to NeurIPS 2022! </td> </tr> </table> </div> </div> <h2> <a href="/blog/" style="color: inherit">latest posts</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Apr 14, 2024</th> <td> <a class="news-title" href="/blog/2024/translanguaging/">Translanguaging</a> </td> </tr> <tr> <th scope="row" style="width: 20%">Mar 17, 2024</th> <td> <a class="news-title" href="/blog/2024/sinilarin-otesi/">SÄ±nÄ±rlarÄ±n Ã¶tesi</a> </td> </tr> <tr> <th scope="row" style="width: 20%">Apr 05, 2021</th> <td> <a class="news-title" href="/blog/2021/bireysellesme/">Bireysellesme</a> </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">submitted</abbr> </div> <div id="hizli2024identification" class="col-sm-8"> <div class="title">Identifying latent state transition in non-linear dynamical systems</div> <div class="author"> Ã‡aÄŸlar HÄ±zlÄ± ,Â  <em>Ã‡aÄŸatay YÄ±ldÄ±z</em> ,Â  Matthias Bethge , and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'ST John, Pekka Marttinen' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems</em> , 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2406.03337" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>This work aims to improve generalization and interpretability of dynamical systems by recovering the underlying lower-dimensional latent states and their time evolutions. Previous work on disentangled representation learning within the realm of dynamical systems focused on the latent states, possibly with linear transition approximations. As such, they cannot identify nonlinear transition dynamics, and hence fail to reliably predict complex future behavior. Inspired by the advances in nonlinear ICA, we propose a state-space modeling framework in which we can identify not just the latent states but also the unknown transition function that maps the past states to the present. We introduce a practical algorithm based on variational auto-encoders and empirically demonstrate in realistic synthetic settings that we can (i) recover latent state dynamics with high accuracy, (ii) correspondingly achieve high future prediction accuracy, and (iii) adapt fast to new environments.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">submitted</abbr> </div> <div id="yildiz2024investigating" class="col-sm-8"> <div class="title">Investigating Continual Pretraining in Large Language Models: Insights and Implications</div> <div class="author"> <em>Ã‡aÄŸatay YÄ±ldÄ±z</em> ,Â  Nishaanth Kanna Ravichandran ,Â  Matthias Bethge , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Beyza Ermis' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In Empirical Methods in Natural Language Processing</em> , 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2402.17400v1.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>This paper studies the evolving domain of Continual Learning (CL) in large language models (LLMs), with a focus on developing strategies for efficient and sustainable training. Our primary emphasis is on continual domain-adaptive pretraining, a process designed to equip LLMs with the ability to integrate new information from various domains while retaining previously learned knowledge and enhancing cross-domain knowledge transfer without relying on domain-specific identification. Unlike previous studies, which mostly concentrate on a limited selection of tasks or domains and primarily aim to address the issue of forgetting, our research evaluates the adaptability and capabilities of LLMs to changing data landscapes in practical scenarios. To this end, we introduce a new benchmark designed to measure the adaptability of LLMs to these evolving data environments, offering a comprehensive framework for evaluation. We examine the impact of model size on learning efficacy and forgetting, as well as how the progression and similarity of emerging domains affect the knowledge transfer within these models. Our findings uncover several key insights: (i) when the sequence of domains shows semantic similarity, continual pretraining enables LLMs to better specialize in the current domain compared to stand-alone fine-tuning, (ii) training across a diverse range of domains enhances both backward and forward knowledge transfer, and (iii) smaller models are particularly sensitive to continual pretraining, showing the most significant rates of both forgetting and learning. We posit that our research marks a shift towards establishing a more realistic benchmark for investigating CL in LLMs, and has the potential to play a key role in guiding the direction of future research in the field.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">CoLLAs</abbr> </div> <div id="dziadzio2024infinite" class="col-sm-8"> <div class="title">Infinite dSprites for Disentangled Continual Learning: Separating Memory Edits from Generalization</div> <div class="author"> Sebastian Dziadzio ,Â  <em>Ã‡aÄŸatay YÄ±ldÄ±z</em> ,Â  Gido Ven , and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Tomasz Trzcinski, Tinne Tuytelaars, Matthias Bethge' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In Lifelong Learning Agents</em> , 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2312.16731v2" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>The ability of machine learning systems to learn continually is hindered by catastrophic forgetting, the tendency of neural networks to overwrite existing knowledge when learning a new task. Continual learning methods alleviate this problem through regularization, parameter isolation, or rehearsal, but they are typically evaluated on benchmarks comprising only a handful of tasks. In contrast, humans are able to learn continually in dynamic, open-world environments, effortlessly achieving one-shot memorization of unfamiliar objects and reliably recognizing them under various transformations. To make progress towards closing this gap, we introduce Infinite dSprites, a parsimonious tool for creating continual classification and disentanglement benchmarks of arbitrary length and with full control over generative factors. We show that over a sufficiently long time horizon, the performance of all major types of continual learning methods deteriorates on this simple benchmark. Thus, Infinite dSprites highlights an important aspect of continual learning that has not received enough attention so far: given a finite modelling capacity and an arbitrarily long learning horizon, efficient learning requires memorizing class-specific information and accumulating knowledge about general mechanisms. In a simple setting with direct supervision on the generative factors, we show how learning class-agnostic transformations offers a way to circumvent catastrophic forgetting and improve classification accuracy over time. Our approach sets the stage for continual learning over hundreds of tasks with explicit control over memorization and forgetting, emphasizing open-set classification and one-shot generalization.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">NeurIPS</abbr> </div> <div id="auzina2023invariant" class="col-sm-8"> <div class="title">Invariant Neural Ordinary Differential Equations</div> <div class="author"> Ilze Amanda Auzina ,Â  <em>Ã‡aÄŸatay YÄ±ldÄ±z</em> ,Â  Sara Magliacane , and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Matthias Bethge, Efstratios Gavves' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems</em> , 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2302.13262.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Latent neural ordinary differential equations have been proven useful for learning non-linear dynamics of arbitrary sequences. In contrast with their mechanistic counterparts, the predictive accuracy of neural ODEs decreases over longer prediction horizons (Rubanova et al., 2019). To mitigate this issue, we propose disentangling dynamic states from time-invariant variables in a completely data-driven way, enabling robust neural ODE models that can generalize across different settings. We show that such variables can control the latent differential function and/or parameterize the mapping from latent variables to observations. By explicitly modeling the time-invariant variables, our framework enables the use of recent advances in representation learning. We demonstrate this by introducing a straightforward self-supervised objective that enhances the learning of these variables. The experiments on low-dimensional oscillating systems and video sequences reveal that our disentangled model achieves improved longterm predictions, when the training data involve sequence-specific factors of variation such as different rotational speeds, calligraphic styles, and friction constants.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">ICLR</abbr> </div> <div id="iakovlev2022latent" class="col-sm-8"> <div class="title">Latent Neural ODEs with Sparse Bayesian Multiple Shooting</div> <div class="author"> Valerii Iakovlev ,Â  <em>Ã‡aÄŸatay YÄ±ldÄ±z</em> ,Â  Markus Heinonen , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Harri LÃ¤hdesmÃ¤ki' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In International Conference on Learning Representations</em> , 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://openreview.net/pdf?id=moIlFZfj_1b" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Training dynamic models, such as neural ODEs, on long trajectories is a hard problem that requires using various tricks, such as trajectory splitting, to make model training work in practice. These methods are often heuristics with poor theoretical justifications, and require iterative manual tuning. We propose a principled multiple shooting technique for neural ODEs that splits the trajectories into manageable short segments, which are optimised in parallel, while ensuring probabilistic control on continuity over consecutive segments. We derive variational inference for our shooting-based latent neural ODE models and propose amortized encodings of irregularly sampled trajectories with a transformer-based recognition network with temporal attention and relative positional encoding. We demonstrate efficient and stable training, and state-of-the-art performance on multiple large-scale benchmark datasets.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">NeurIPS</abbr> </div> <div id="yildiz2022learning" class="col-sm-8"> <div class="title">Learning Interacting Dynamical Systems with Latent Gaussian Process ODEs</div> <div class="author"> <em>Ã‡aÄŸatay YÄ±ldÄ±z</em> ,Â  Melih Kandemir ,Â  andÂ  Barbara Rakitsch </div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems</em> , 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2205.11894.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/boschresearch/iGPODE" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>We study uncertainty-aware modeling of continuous-time dynamics of interacting objects. We introduce a new model that decomposes independent dynamics of single objects accurately from their interactions. By employing latent Gaussian process ordinary differential equations, our model infers both independent dynamics and their interactions with reliable uncertainty estimates. In our formulation, each object is represented as a graph node and interactions are modeled by accumulating the messages coming from neighboring objects. We show that efficient inference of such a complex network of variables is possible with modern variational sparse Gaussian process inference techniques. We empirically demonstrate that our model improves the reliability of long-term predictions over neural network based alternatives and it successfully handles missing dynamic or static information. Furthermore, we observe that only our model can successfully encapsulate independent dynamics and interaction information in distinct functions and show the benefit from this disentanglement in extrapolation scenarios.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">UAI</abbr> </div> <div id="hegde2021bayesian" class="col-sm-8"> <div class="title">Variational multiple shooting for Bayesian ODEs with Gaussian processes</div> <div class="author"> Pashupati Hedge ,Â  <em>Ã‡aÄŸatay YÄ±ldÄ±z</em> ,Â  Harri Lahdesmaki , and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Samuel Kaski, Markus Heinonen' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>In Uncertainty in Artificial Intelligence</em> , 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2106.10905.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/hegdepashupati/gaussian-process-odes" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Recent machine learning advances have proposed black-box estimation of unknown continuous-time system dynamics directly from data. However, earlier works are based on approximative ODE solutions or point estimates. We propose a novel Bayesian nonparametric model that uses Gaussian processes to infer posteriors of unknown ODE systems directly from data. We derive sparse variational inference with decoupled functional sampling to represent vector field posteriors. We also introduce a probabilistic shooting augmentation to enable efficient inference from arbitrarily long trajectories. The method demonstrates the benefit of computing vector field posteriors, with predictive uncertainty scores outperforming alternative methods on multiple ODE learning tasks.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">thesis</abbr> </div> <div id="YÄ±ldÄ±z2022" class="col-sm-8"> <div class="title">Differential Equations for Machine Learning</div> <div class="author"> <em>Ã‡aÄŸatay YÄ±ldÄ±z</em> </div> <div class="periodical"> 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="http://urn.fi/URN:ISBN:978-952-64-0666-4" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://aaltodoc.aalto.fi/bitstream/handle/123456789/112291/isbn9789526406664.pdf?sequence=1&amp;isAllowed=y" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">ICML</abbr> </div> <div id="yildiz2021continuous" class="col-sm-8"> <div class="title">Continuous-time Model-based Reinforcement Learning</div> <div class="author"> <em>Ã‡aÄŸatay YÄ±ldÄ±z</em> ,Â  Markus Heinonen ,Â  andÂ  Harri Lahdesmaki </div> <div class="periodical"> <em>In International Conference on Machine Learning</em> , 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2102.04764.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/cagatayyildiz/oderl" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Model-based reinforcement learning (MBRL) approaches rely on discrete-time state transition models whereas physical systems and the vast majority of control tasks operate in continuous-time. To avoid time-discretization approximation of the underlying process, we propose a continuous-time MBRL framework based on a novel actor-critic method. Our approach also infers the unknown state evolution differentials with Bayesian neural ordinary differential equations (ODE) to account for epistemic uncertainty. We implement and test our method on a new ODE-RL suite that explicitly solves continuous-time control systems. Our experiments illustrate that the model is robust against irregular and noisy data, is sample-efficient, and can solve control problems which pose challenges to discrete-time MBRL methods. </p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">NeurIPS</abbr> </div> <div id="yildiz2019deep" class="col-sm-8"> <div class="title">ODE2VAE: Deep generative second order ODEs with Bayesian neural networks</div> <div class="author"> <em>Ã‡aÄŸatay YÄ±ldÄ±z</em> ,Â  Markus Heinonen ,Â  andÂ  Harri Lahdesmaki </div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems</em> , 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://papers.nips.cc/paper/2019/hash/99a401435dcb65c4008d3ad22c8cdad0-Abstract.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://papers.nips.cc/paper/2019/file/99a401435dcb65c4008d3ad22c8cdad0-Paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://papers.nips.cc/paper/2019/file/99a401435dcb65c4008d3ad22c8cdad0-Supplemental.zip" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Supp</a> <a href="https://github.com/cagatayyildiz/ODE2VAE" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://github.com/cagatayyildiz/ODE2VAE/blob/master/ode2vae_poster.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Poster</a> </div> <div class="abstract hidden"> <p>We present Ordinary Differential Equation Variational Auto-Encoder (ODE2VAE), a latent second order ODE model for high-dimensional sequential data. Leveraging the advances in deep generative models, ODE2VAE can simultaneously learn the embedding of high dimensional trajectories and infer arbitrarily complex continuous-time latent dynamics. Our model explicitly decomposes the latent space into momentum and position components and solves a second order ODE system, which is in contrast to recurrent neural network (RNN) based time series models and recently proposed black-box ODE techniques. In order to account for uncertainty, we propose probabilistic latent ODE dynamics parameterized by deep Bayesian neural networks. We demonstrate our approach on motion capture, image rotation, and bouncing balls datasets. We achieve state-of-the-art performance in long term motion prediction and imputation tasks.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">ICML</abbr> </div> <div id="heinonen18learning" class="col-sm-8"> <div class="title">Learning unknown ODE models with Gaussian processes</div> <div class="author"> Markus Heinonen ,Â  <em>Ã‡aÄŸatay YÄ±ldÄ±z</em> ,Â  Henrik MannerstrÃ¶m , and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Jukka Intosalmi, Harri LÃ¤hdesmÃ¤ki' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>In International Conference on Machine Learning</em> , 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://papers.nips.cc/paper/2019/hash/99a401435dcb65c4008d3ad22c8cdad0-Abstract.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="http://proceedings.mlr.press/v80/heinonen18a/heinonen18a.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="http://proceedings.mlr.press/v80/heinonen18a/heinonen18a-supp.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Supp</a> <a href="https://github.com/cagatayyildiz/npde/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://github.com/cagatayyildiz/npde/blob/master/npode_poster.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Poster</a> </div> <div class="abstract hidden"> <p>In conventional ODE modelling coefficients of an equation driving the system state forward in time are estimated. However, for many complex systems it is practically impossible to determine the equations or interactions governing the underlying dynamics. In these settings, parametric ODE model cannot be formulated. Here, we overcome this issue by introducing a novel paradigm of nonparametric ODE modelling that can learn the underlying dynamics of arbitrary continuous-time systems without prior knowledge. We propose to learn non-linear, unknown differential functions from state observations using Gaussian process vector fields within the exact ODE formalism. We demonstrate the modelâ€™s capabilities to infer dynamics from sparse data and to simulate the system forward into future.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">ICML</abbr> </div> <div id="simsekli18learning" class="col-sm-8"> <div class="title">Asynchronous Stochastic Quasi-Newton MCMC for Non-Convex Optimization</div> <div class="author"> Umut Simsekli ,Â  <em>Ã‡aÄŸatay YÄ±ldÄ±z</em> ,Â  Than Huy Nguyen , and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Taylan Cemgil, Gael Richard' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>In International Conference on Machine Learning</em> , 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://proceedings.mlr.press/v80/simsekli18a" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="http://proceedings.mlr.press/v80/simsekli18a/simsekli18a.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="http://proceedings.mlr.press/v80/simsekli18a/simsekli18a-supp.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Supp</a> <a href="/assets/pdf/aslbfgs_poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="abstract hidden"> <p>Recent studies have illustrated that stochastic gradient Markov Chain Monte Carlo techniques have a strong potential in non-convex optimization, where local and global convergence guarantees can be shown under certain conditions. By building up on this recent theory, in this study, we develop an asynchronous-parallel stochastic L-BFGS algorithm for non-convex optimization. The proposed algorithm is suitable for both distributed and shared-memory settings. We provide formal theoretical analysis and show that the proposed method achieves an ergodic convergence rate of O(1/\sqrtN) (N being the total number of iterations) and it can achieve a linear speedup under certain conditions. We perform several experiments on both synthetic and real datasets. The results support our theory and show that the proposed algorithm provides a significant speedup over the recently proposed synchronous distributed L-BFGS algorithm.</p> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%63%61%67%61%74%61%79.%79%69%6C%64%69%7A@%75%6E%69-%74%75%65%62%69%6E%67%65%6E.%64%65" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=dNloPBUAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/cagatayyildiz" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://twitter.com/CgtyYldz" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> <a href="/feed.xml" title="RSS Feed"><i class="fa-solid fa-square-rss"></i></a> </div> <div class="contact-note">Feel free to drop an e-mail on anything! </div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> Â© Copyright 2024 Ã‡aÄŸatay YÄ±ldÄ±z. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?4a129fbf39254905f505c7246e641eaf"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>